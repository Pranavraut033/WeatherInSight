# WeatherInsight DAG Configuration
# Centralized configuration for Airflow DAGs

# Product types to orchestrate
product_types:
  - air_temperature
  - precipitation
  - wind
  - pressure
  - moisture

# Dataset version patterns
# Use Airflow template variables: {{ ds }}, {{ execution_date }}, etc.
versioning:
  raw_pattern: "{{ execution_date.year }}Q{{ ((execution_date.month - 1) // 3) + 1 }}_raw_v1"
  staged_pattern: "{{ execution_date.year }}Q{{ ((execution_date.month - 1) // 3) + 1 }}_staged_v1"
  curated_pattern: "{{ execution_date.year }}Q{{ ((execution_date.month - 1) // 3) + 1 }}_v1"

# Retry policies
retries:
  ingestion: 3
  processing: 2
  aggregation: 2
  data_quality: 1

retry_delay:
  minutes: 5

# SLA configuration (service level agreements)
sla:
  ingestion_hours: 6
  processing_hours: 4
  aggregation_hours: 2
  pipeline_hours: 12

# Resource pools
pools:
  spark_jobs: 3  # Max concurrent Spark jobs
  api_calls: 5   # Max concurrent external API calls

# Email alerts
email:
  on_failure: true
  on_retry: false
  on_success: false
  recipients:
    - data-engineering@weatherinsight.local
    - alerts@weatherinsight.local

# Spark configuration
spark:
  master: "spark://spark-master:7077"
  deploy_mode: "client"
  driver_memory: "2g"
  executor_memory: "4g"
  executor_cores: 2

# Data quality thresholds
quality_thresholds:
  min_rows_per_quarter: 100
  max_null_percentage: 15.0  # Max 15% nulls in critical columns
  min_stations_per_quarter: 50

# Backfill configuration
backfill:
  default_start_year: 2020
  default_end_year: 2024
  default_quarters: [1, 2, 3, 4]
  max_parallel_quarters: 4
